{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Analyst Take Home Exercise for Colton Radenbaugh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3 as db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Explore the Data\n",
    "-  Initially here I'd like to get a high level view of what is in each of these csv's with an understanding what data type the columns are, unique values, amount of nulls, and if there are duplicate values where I might not expect to find them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I'm pulling in the provided csv data files that for the exercie. First through panadas for some initial data exploration and then I'll add them to a SQLite database so I can join and analyze them further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.read_csv('data_files\\\\PRODUCTS_TAKEHOME.csv')\n",
    "transaction_df = pd.read_csv('data_files\\\\TRANSACTION_TAKEHOME.csv')\n",
    "user_df = pd.read_csv('data_files\\\\USER_TAKEHOME.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CATEGORY_1              CATEGORY_2                   CATEGORY_3  \\\n",
      "0  Health & Wellness           Sexual Health  Conductivity Gels & Lotions   \n",
      "1             Snacks           Puffed Snacks         Cheese Curls & Puffs   \n",
      "2  Health & Wellness               Hair Care        Hair Care Accessories   \n",
      "3  Health & Wellness               Oral Care                   Toothpaste   \n",
      "4  Health & Wellness  Medicines & Treatments               Essential Oils   \n",
      "\n",
      "  CATEGORY_4                                       MANUFACTURER  \\\n",
      "0        NaN                                                NaN   \n",
      "1        NaN                                                NaN   \n",
      "2        NaN                           PLACEHOLDER MANUFACTURER   \n",
      "3        NaN                                  COLGATE-PALMOLIVE   \n",
      "4        NaN  MAPLE HOLISTICS AND HONEYDEW PRODUCTS INTERCHA...   \n",
      "\n",
      "             BRAND       BARCODE  \n",
      "0              NaN  7.964944e+11  \n",
      "1              NaN  2.327801e+10  \n",
      "2          ELECSOP  4.618178e+11  \n",
      "3          COLGATE  3.500047e+10  \n",
      "4  MAPLE HOLISTICS  8.068109e+11  \n",
      "----------------                         -------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 845552 entries, 0 to 845551\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   CATEGORY_1    845441 non-null  object \n",
      " 1   CATEGORY_2    844128 non-null  object \n",
      " 2   CATEGORY_3    784986 non-null  object \n",
      " 3   CATEGORY_4    67459 non-null   object \n",
      " 4   MANUFACTURER  619078 non-null  object \n",
      " 5   BRAND         619080 non-null  object \n",
      " 6   BARCODE       841527 non-null  float64\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 45.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(products_df.head())\n",
    "print('----------------                         -------------------------')\n",
    "print(products_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This PRODUCTS data set seems pretty straight forward as a dimesions table for the different type of items that we could find with a user's purchases. \n",
    "There are few potential issues with nulls that I think could cause some issues around null Barcodes which appears to be the key for joining this table to the Transactions data set after looking at the ERM. Also, products that have null values for any of the other dimesions will cause issues if I try and aggregate results on those dimensions, so I would need to omit those nulls when doing aggregation or bucket them into a catch all \"other\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY_1</th>\n",
       "      <th>CATEGORY_2</th>\n",
       "      <th>CATEGORY_3</th>\n",
       "      <th>CATEGORY_4</th>\n",
       "      <th>MANUFACTURER</th>\n",
       "      <th>BRAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>845441</td>\n",
       "      <td>844128</td>\n",
       "      <td>784986</td>\n",
       "      <td>67459</td>\n",
       "      <td>619078</td>\n",
       "      <td>619080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27</td>\n",
       "      <td>121</td>\n",
       "      <td>344</td>\n",
       "      <td>127</td>\n",
       "      <td>4354</td>\n",
       "      <td>8122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>Candy</td>\n",
       "      <td>Confection Candy</td>\n",
       "      <td>Lip Balms</td>\n",
       "      <td>PLACEHOLDER MANUFACTURER</td>\n",
       "      <td>REM BRAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>512695</td>\n",
       "      <td>121036</td>\n",
       "      <td>56965</td>\n",
       "      <td>9737</td>\n",
       "      <td>86902</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CATEGORY_1 CATEGORY_2        CATEGORY_3 CATEGORY_4  \\\n",
       "count              845441     844128            784986      67459   \n",
       "unique                 27        121               344        127   \n",
       "top     Health & Wellness      Candy  Confection Candy  Lip Balms   \n",
       "freq               512695     121036             56965       9737   \n",
       "\n",
       "                    MANUFACTURER      BRAND  \n",
       "count                     619078     619080  \n",
       "unique                      4354       8122  \n",
       "top     PLACEHOLDER MANUFACTURER  REM BRAND  \n",
       "freq                       86902      20813  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.describe(include = \"object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Could be interesting to explore the vast amout of Health & Wellness products, since they are more than half of the data set. Though I'll have to see how prevalent they are in the transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alcohol',\n",
       " 'Animals & Pet Supplies',\n",
       " 'Apparel & Accessories',\n",
       " 'Arts & Entertainment',\n",
       " 'Baby & Toddler',\n",
       " 'Beauty',\n",
       " 'Beverages',\n",
       " 'Dairy',\n",
       " 'Deli & Bakery',\n",
       " 'Electronics',\n",
       " 'Frozen',\n",
       " 'Health & Wellness',\n",
       " 'Home & Garden',\n",
       " 'Household Supplies',\n",
       " 'Luggage & Bags',\n",
       " 'Mature',\n",
       " 'Meat & Seafood',\n",
       " 'Media',\n",
       " 'Needs Review',\n",
       " 'Office & School',\n",
       " 'Pantry',\n",
       " 'Produce',\n",
       " 'Restaurant',\n",
       " 'Snacks',\n",
       " 'Sporting Goods',\n",
       " 'Toys & Games',\n",
       " 'Vehicles & Parts',\n",
       " 'nan']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(products_df['CATEGORY_1'].astype(str).unique())\n",
    "# sorted(products_df['CATEGORY_2'].astype(str).unique()) \n",
    "# sorted(products_df['CATEGORY_3'].astype(str).unique()) \n",
    "# sorted(products_df['CATEGORY_4'].astype(str).unique()) \n",
    "# sorted(products_df['MANUFACTURER'].astype(str).unique()) \n",
    "# sorted(products_df['BRAND'].astype(str).unique()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After taking a scan of the unique values for all of the labeling columns of a product the data seems clean in the fact that there appears to be no issue with labels seeming to be unique but are in fact duplicates that only differ with the addition of a space or whitespace character. This gives me confidence for any aggregation that may need to be done on these dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         ID               CREATED_DATE  \\\n",
      "0  5ef3b4f17053ab141787697d  2020-06-24 20:17:54.000 Z   \n",
      "1  5ff220d383fcfc12622b96bc  2021-01-03 19:53:55.000 Z   \n",
      "2  6477950aa55bb77a0e27ee10  2023-05-31 18:42:18.000 Z   \n",
      "3  658a306e99b40f103b63ccf8  2023-12-26 01:46:22.000 Z   \n",
      "4  653cf5d6a225ea102b7ecdc2  2023-10-28 11:51:50.000 Z   \n",
      "\n",
      "                  BIRTH_DATE STATE LANGUAGE  GENDER  \n",
      "0  2000-08-11 00:00:00.000 Z    CA   es-419  female  \n",
      "1  2001-09-24 04:00:00.000 Z    PA       en  female  \n",
      "2  1994-10-28 00:00:00.000 Z    FL   es-419  female  \n",
      "3                        NaN    NC       en     NaN  \n",
      "4  1972-03-19 00:00:00.000 Z    PA       en  female  \n",
      "----------------                         -------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   ID            100000 non-null  object\n",
      " 1   CREATED_DATE  100000 non-null  object\n",
      " 2   BIRTH_DATE    96325 non-null   object\n",
      " 3   STATE         95188 non-null   object\n",
      " 4   LANGUAGE      69492 non-null   object\n",
      " 5   GENDER        94108 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(user_df.head())\n",
    "print('----------------                         -------------------------')\n",
    "print(user_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>GENDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>96325</td>\n",
       "      <td>95188</td>\n",
       "      <td>69492</td>\n",
       "      <td>94108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100000</td>\n",
       "      <td>99942</td>\n",
       "      <td>54721</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5ef3b4f17053ab141787697d</td>\n",
       "      <td>2023-01-12 18:30:15.000 Z</td>\n",
       "      <td>1970-01-01 00:00:00.000 Z</td>\n",
       "      <td>TX</td>\n",
       "      <td>en</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1272</td>\n",
       "      <td>9028</td>\n",
       "      <td>63403</td>\n",
       "      <td>64240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID               CREATED_DATE  \\\n",
       "count                     100000                     100000   \n",
       "unique                    100000                      99942   \n",
       "top     5ef3b4f17053ab141787697d  2023-01-12 18:30:15.000 Z   \n",
       "freq                           1                          2   \n",
       "\n",
       "                       BIRTH_DATE  STATE LANGUAGE  GENDER  \n",
       "count                       96325  95188    69492   94108  \n",
       "unique                      54721     52        2      11  \n",
       "top     1970-01-01 00:00:00.000 Z     TX       en  female  \n",
       "freq                         1272   9028    63403   64240  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.describe(include= \"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"My gender isn't listed\",\n",
       " 'Non-Binary',\n",
       " 'Prefer not to say',\n",
       " 'female',\n",
       " 'male',\n",
       " 'nan',\n",
       " 'non_binary',\n",
       " 'not_listed',\n",
       " 'not_specified',\n",
       " 'prefer_not_to_say',\n",
       " 'transgender',\n",
       " 'unknown']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(user_df['GENDER'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dimesion columns for the user data seems clean with no whitespace duplicated values for GENDER and the LANGUAGE dimesnion only has 2 unique values of \"en\" and \"es-419\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             RECEIPT_ID PURCHASE_DATE  \\\n",
      "0  0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21   \n",
      "1  0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20   \n",
      "2  00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18   \n",
      "3  000239aa-3478-453d-801e-66a82e39c8af    2024-06-18   \n",
      "4  00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04   \n",
      "\n",
      "                   SCAN_DATE STORE_NAME                   USER_ID  \\\n",
      "0  2024-08-21 14:19:06.539 Z    WALMART  63b73a7f3d310dceeabd4758   \n",
      "1  2024-07-20 09:50:24.206 Z       ALDI  62c08877baa38d1a1f6c211a   \n",
      "2  2024-08-19 15:38:56.813 Z    WALMART  60842f207ac8b7729e472020   \n",
      "3  2024-06-19 11:03:37.468 Z  FOOD LION  63fcd7cea4f8442c3386b589   \n",
      "4  2024-07-05 15:56:43.549 Z   RANDALLS  6193231ae9b3d75037b0f928   \n",
      "\n",
      "        BARCODE FINAL_QUANTITY FINAL_SALE  \n",
      "0  1.530001e+10           1.00             \n",
      "1           NaN           zero       1.49  \n",
      "2  7.874223e+10           1.00             \n",
      "3  7.833997e+11           zero       3.49  \n",
      "4  4.790050e+10           1.00             \n",
      "----------------                         -------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   RECEIPT_ID      50000 non-null  object \n",
      " 1   PURCHASE_DATE   50000 non-null  object \n",
      " 2   SCAN_DATE       50000 non-null  object \n",
      " 3   STORE_NAME      50000 non-null  object \n",
      " 4   USER_ID         50000 non-null  object \n",
      " 5   BARCODE         44238 non-null  float64\n",
      " 6   FINAL_QUANTITY  50000 non-null  object \n",
      " 7   FINAL_SALE      50000 non-null  object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 3.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(transaction_df.head())\n",
    "print('----------------                         -------------------------')\n",
    "print(transaction_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Glad to see there are no null values for the user_id assciated with the purchases, though the lack of Barcodes for a few thousand items could be an issue for summarizing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECEIPT_ID</th>\n",
       "      <th>PURCHASE_DATE</th>\n",
       "      <th>SCAN_DATE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>FINAL_QUANTITY</th>\n",
       "      <th>FINAL_SALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>24440</td>\n",
       "      <td>89</td>\n",
       "      <td>24440</td>\n",
       "      <td>954</td>\n",
       "      <td>17694</td>\n",
       "      <td>87</td>\n",
       "      <td>1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>bedac253-2256-461b-96af-267748e6cecf</td>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>2024-09-08 20:00:42.348 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>64e62de5ca929250373e6cf5</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>12</td>\n",
       "      <td>774</td>\n",
       "      <td>12</td>\n",
       "      <td>21326</td>\n",
       "      <td>22</td>\n",
       "      <td>35698</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  RECEIPT_ID PURCHASE_DATE  \\\n",
       "count                                  50000         50000   \n",
       "unique                                 24440            89   \n",
       "top     bedac253-2256-461b-96af-267748e6cecf    2024-06-15   \n",
       "freq                                      12           774   \n",
       "\n",
       "                        SCAN_DATE STORE_NAME                   USER_ID  \\\n",
       "count                       50000      50000                     50000   \n",
       "unique                      24440        954                     17694   \n",
       "top     2024-09-08 20:00:42.348 Z    WALMART  64e62de5ca929250373e6cf5   \n",
       "freq                           12      21326                        22   \n",
       "\n",
       "       FINAL_QUANTITY FINAL_SALE  \n",
       "count           50000      50000  \n",
       "unique             87       1435  \n",
       "top              1.00             \n",
       "freq            35698      12500  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_df.describe(include= \"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.01',\n",
       " '0.04',\n",
       " '0.09',\n",
       " '0.23',\n",
       " '0.24',\n",
       " '0.28',\n",
       " '0.35',\n",
       " '0.46',\n",
       " '0.48',\n",
       " '0.51',\n",
       " '0.53',\n",
       " '0.62',\n",
       " '0.65',\n",
       " '0.70',\n",
       " '0.83',\n",
       " '0.86',\n",
       " '0.87',\n",
       " '0.94',\n",
       " '0.97',\n",
       " '0.99',\n",
       " '1.00',\n",
       " '1.07',\n",
       " '1.08',\n",
       " '1.13',\n",
       " '1.18',\n",
       " '1.22',\n",
       " '1.23',\n",
       " '1.24',\n",
       " '1.28',\n",
       " '1.34',\n",
       " '1.35',\n",
       " '1.37',\n",
       " '1.40',\n",
       " '1.44',\n",
       " '1.47',\n",
       " '1.50',\n",
       " '1.54',\n",
       " '1.69',\n",
       " '1.80',\n",
       " '1.81',\n",
       " '1.88',\n",
       " '1.89',\n",
       " '1.93',\n",
       " '1.99',\n",
       " '10.00',\n",
       " '12.00',\n",
       " '16.00',\n",
       " '18.00',\n",
       " '2.00',\n",
       " '2.04',\n",
       " '2.10',\n",
       " '2.11',\n",
       " '2.17',\n",
       " '2.18',\n",
       " '2.19',\n",
       " '2.20',\n",
       " '2.25',\n",
       " '2.27',\n",
       " '2.34',\n",
       " '2.39',\n",
       " '2.52',\n",
       " '2.54',\n",
       " '2.57',\n",
       " '2.58',\n",
       " '2.60',\n",
       " '2.61',\n",
       " '2.75',\n",
       " '2.83',\n",
       " '2.89',\n",
       " '2.93',\n",
       " '276.00',\n",
       " '3.00',\n",
       " '3.02',\n",
       " '3.11',\n",
       " '3.24',\n",
       " '3.33',\n",
       " '3.69',\n",
       " '4.00',\n",
       " '4.55',\n",
       " '5.00',\n",
       " '5.53',\n",
       " '6.00',\n",
       " '6.22',\n",
       " '7.00',\n",
       " '8.00',\n",
       " '9.00',\n",
       " 'zero']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transaction_df['FINAL_QUANTITY'].min()\n",
    "# transaction_df['FINAL_SALE'].max()\n",
    "# sorted(transaction_df['FINAL_SALE'].astype(str).unique())\n",
    "sorted(transaction_df['FINAL_QUANTITY'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A potential issue with the FINAL_QUANTITY is the presence of 'zero' among all of the float (or demical) values, I think I will change those to 0.00 before putting this csv in to a SQLite db\n",
    "- And with FINAL_SALE the entry of ' ' seems odd, I'm not sure if this is intential or that those should be 0.00 or NaN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECEIPT_ID</th>\n",
       "      <th>PURCHASE_DATE</th>\n",
       "      <th>SCAN_DATE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>BARCODE</th>\n",
       "      <th>FINAL_QUANTITY</th>\n",
       "      <th>FINAL_SALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000d256-4041-4a3e-adc4-5623fb6e0c99</td>\n",
       "      <td>2024-08-21</td>\n",
       "      <td>2024-08-21 14:19:06.539 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>63b73a7f3d310dceeabd4758</td>\n",
       "      <td>1.530001e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00017e0a-7851-42fb-bfab-0baa96e23586</td>\n",
       "      <td>2024-08-18</td>\n",
       "      <td>2024-08-19 15:38:56.813 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>60842f207ac8b7729e472020</td>\n",
       "      <td>7.874223e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>2024-07-05 15:56:43.549 Z</td>\n",
       "      <td>RANDALLS</td>\n",
       "      <td>6193231ae9b3d75037b0f928</td>\n",
       "      <td>4.790050e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>000550b2-1480-4c07-950f-ff601f242152</td>\n",
       "      <td>2024-07-06</td>\n",
       "      <td>2024-07-06 19:27:48.586 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>5f850bc9cf9431165f3ac175</td>\n",
       "      <td>4.920091e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>000e1d35-15e5-46c6-b6b3-33653ed3d27e</td>\n",
       "      <td>2024-08-13</td>\n",
       "      <td>2024-08-13 18:21:07.931 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>61a6d926f998e47aad33db66</td>\n",
       "      <td>5.200001e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>ffeb1ff4-0db9-4cb9-9574-20ec2db3e5ad</td>\n",
       "      <td>2024-08-25</td>\n",
       "      <td>2024-08-25 12:43:19.456 Z</td>\n",
       "      <td>FOOD CITY</td>\n",
       "      <td>6246d0d989dfe41b042f2d9d</td>\n",
       "      <td>2.484283e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>ffec42ba-c71d-44da-b8d0-eb529632e87a</td>\n",
       "      <td>2024-06-17</td>\n",
       "      <td>2024-06-17 11:17:21.971 Z</td>\n",
       "      <td>WINCO FOODS</td>\n",
       "      <td>6632c5871be3d689ceb875c7</td>\n",
       "      <td>4.119601e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>fff15a3d-25ea-4c36-b84a-91eb4157daf9</td>\n",
       "      <td>2024-07-19</td>\n",
       "      <td>2024-07-23 22:43:04.589 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>6254a7ea3f2afd3c2fd53d22</td>\n",
       "      <td>7.874213e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>fff6c6c8-e002-4262-85ea-25849d9721db</td>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>2024-09-06 18:39:03.161 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>6220b111e9e82c0c6bc24534</td>\n",
       "      <td>7.874237e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>fffbfb2a-7c1f-41c9-a5da-628fa7fcc746</td>\n",
       "      <td>2024-07-28</td>\n",
       "      <td>2024-07-28 11:47:34.180 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>62a0c8f7d966665570351bb8</td>\n",
       "      <td>1.300001e+10</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 RECEIPT_ID PURCHASE_DATE  \\\n",
       "0      0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21   \n",
       "2      00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18   \n",
       "4      00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04   \n",
       "6      000550b2-1480-4c07-950f-ff601f242152    2024-07-06   \n",
       "8      000e1d35-15e5-46c6-b6b3-33653ed3d27e    2024-08-13   \n",
       "...                                     ...           ...   \n",
       "24990  ffeb1ff4-0db9-4cb9-9574-20ec2db3e5ad    2024-08-25   \n",
       "24992  ffec42ba-c71d-44da-b8d0-eb529632e87a    2024-06-17   \n",
       "24994  fff15a3d-25ea-4c36-b84a-91eb4157daf9    2024-07-19   \n",
       "24996  fff6c6c8-e002-4262-85ea-25849d9721db    2024-08-30   \n",
       "24998  fffbfb2a-7c1f-41c9-a5da-628fa7fcc746    2024-07-28   \n",
       "\n",
       "                       SCAN_DATE   STORE_NAME                   USER_ID  \\\n",
       "0      2024-08-21 14:19:06.539 Z      WALMART  63b73a7f3d310dceeabd4758   \n",
       "2      2024-08-19 15:38:56.813 Z      WALMART  60842f207ac8b7729e472020   \n",
       "4      2024-07-05 15:56:43.549 Z     RANDALLS  6193231ae9b3d75037b0f928   \n",
       "6      2024-07-06 19:27:48.586 Z      WALMART  5f850bc9cf9431165f3ac175   \n",
       "8      2024-08-13 18:21:07.931 Z      WALMART  61a6d926f998e47aad33db66   \n",
       "...                          ...          ...                       ...   \n",
       "24990  2024-08-25 12:43:19.456 Z    FOOD CITY  6246d0d989dfe41b042f2d9d   \n",
       "24992  2024-06-17 11:17:21.971 Z  WINCO FOODS  6632c5871be3d689ceb875c7   \n",
       "24994  2024-07-23 22:43:04.589 Z      WALMART  6254a7ea3f2afd3c2fd53d22   \n",
       "24996  2024-09-06 18:39:03.161 Z      WALMART  6220b111e9e82c0c6bc24534   \n",
       "24998  2024-07-28 11:47:34.180 Z      WALMART  62a0c8f7d966665570351bb8   \n",
       "\n",
       "            BARCODE FINAL_QUANTITY FINAL_SALE  \n",
       "0      1.530001e+10           1.00             \n",
       "2      7.874223e+10           1.00             \n",
       "4      4.790050e+10           1.00             \n",
       "6      4.920091e+10           1.00             \n",
       "8      5.200001e+10           1.00             \n",
       "...             ...            ...        ...  \n",
       "24990  2.484283e+10           1.00             \n",
       "24992  4.119601e+10           1.00             \n",
       "24994  7.874213e+10           1.00             \n",
       "24996  7.874237e+10           1.00             \n",
       "24998  1.300001e+10           1.00             \n",
       "\n",
       "[12500 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_df[transaction_df['FINAL_SALE']== ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECEIPT_ID</th>\n",
       "      <th>PURCHASE_DATE</th>\n",
       "      <th>SCAN_DATE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>BARCODE</th>\n",
       "      <th>FINAL_QUANTITY</th>\n",
       "      <th>FINAL_SALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001455d-7a92-4a7b-a1d2-c747af1c8fd3</td>\n",
       "      <td>2024-07-20</td>\n",
       "      <td>2024-07-20 09:50:24.206 Z</td>\n",
       "      <td>ALDI</td>\n",
       "      <td>62c08877baa38d1a1f6c211a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0010d87d-1ad2-4e5e-9a25-cec736919d15</td>\n",
       "      <td>2024-08-04</td>\n",
       "      <td>2024-08-04 18:01:47.787 Z</td>\n",
       "      <td>ALDI</td>\n",
       "      <td>66686fc2e04f743a096ea808</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>002ee298-d907-40ca-921a-556468571f76</td>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>2024-07-16 16:42:19.211 Z</td>\n",
       "      <td>ALDI</td>\n",
       "      <td>63de64b1dcb50fbd3084f142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00326689-e763-4b27-9ad5-202fc93609e2</td>\n",
       "      <td>2024-06-19</td>\n",
       "      <td>2024-06-20 08:59:38.397 Z</td>\n",
       "      <td>ALDI</td>\n",
       "      <td>6158642597d737581b5d30ee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>00a9e033-e49d-45d6-990e-90631f82775e</td>\n",
       "      <td>2024-09-05</td>\n",
       "      <td>2024-09-05 11:10:54.831 Z</td>\n",
       "      <td>ALDI</td>\n",
       "      <td>5d4f08e962fb4a4a58574e7f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49959</th>\n",
       "      <td>45575fc2-6ba3-4913-bdf2-05814e4309e0</td>\n",
       "      <td>2024-06-20</td>\n",
       "      <td>2024-06-20 11:56:29.486 Z</td>\n",
       "      <td>SUPERMERCADOS ECONO</td>\n",
       "      <td>618c25125e388d4f513334b9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49960</th>\n",
       "      <td>7a36db68-c8a7-4b29-b1c2-4cb51ad9f42a</td>\n",
       "      <td>2024-08-29</td>\n",
       "      <td>2024-08-29 14:39:07.868 Z</td>\n",
       "      <td>DOLLAR TREE STORES INC</td>\n",
       "      <td>665e2f887c0469953bfbdb5b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49962</th>\n",
       "      <td>d7cf611f-f07d-4e3d-9a5d-aacc0d56a4a7</td>\n",
       "      <td>2024-07-21</td>\n",
       "      <td>2024-07-21 10:31:52.403 Z</td>\n",
       "      <td>ALDI</td>\n",
       "      <td>61a8f120f6305b3dade12c15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49963</th>\n",
       "      <td>e79c254d-1bf0-4471-8e79-4f52c6b81481</td>\n",
       "      <td>2024-08-24</td>\n",
       "      <td>2024-08-26 15:21:15.492 Z</td>\n",
       "      <td>DOLLAR TREE STORES INC</td>\n",
       "      <td>62f6799b30b23c82198fa01c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49994</th>\n",
       "      <td>6cdf3c1a-78b3-4fb0-85fd-52e2f5b4731c</td>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>2024-07-01 11:00:39.769 Z</td>\n",
       "      <td>HARRIS TEETER</td>\n",
       "      <td>5de7ec93ca63cc17893cdd14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5762 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 RECEIPT_ID PURCHASE_DATE  \\\n",
       "1      0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20   \n",
       "9      0010d87d-1ad2-4e5e-9a25-cec736919d15    2024-08-04   \n",
       "17     002ee298-d907-40ca-921a-556468571f76    2024-07-15   \n",
       "18     00326689-e763-4b27-9ad5-202fc93609e2    2024-06-19   \n",
       "60     00a9e033-e49d-45d6-990e-90631f82775e    2024-09-05   \n",
       "...                                     ...           ...   \n",
       "49959  45575fc2-6ba3-4913-bdf2-05814e4309e0    2024-06-20   \n",
       "49960  7a36db68-c8a7-4b29-b1c2-4cb51ad9f42a    2024-08-29   \n",
       "49962  d7cf611f-f07d-4e3d-9a5d-aacc0d56a4a7    2024-07-21   \n",
       "49963  e79c254d-1bf0-4471-8e79-4f52c6b81481    2024-08-24   \n",
       "49994  6cdf3c1a-78b3-4fb0-85fd-52e2f5b4731c    2024-06-26   \n",
       "\n",
       "                       SCAN_DATE              STORE_NAME  \\\n",
       "1      2024-07-20 09:50:24.206 Z                    ALDI   \n",
       "9      2024-08-04 18:01:47.787 Z                    ALDI   \n",
       "17     2024-07-16 16:42:19.211 Z                    ALDI   \n",
       "18     2024-06-20 08:59:38.397 Z                    ALDI   \n",
       "60     2024-09-05 11:10:54.831 Z                    ALDI   \n",
       "...                          ...                     ...   \n",
       "49959  2024-06-20 11:56:29.486 Z     SUPERMERCADOS ECONO   \n",
       "49960  2024-08-29 14:39:07.868 Z  DOLLAR TREE STORES INC   \n",
       "49962  2024-07-21 10:31:52.403 Z                    ALDI   \n",
       "49963  2024-08-26 15:21:15.492 Z  DOLLAR TREE STORES INC   \n",
       "49994  2024-07-01 11:00:39.769 Z           HARRIS TEETER   \n",
       "\n",
       "                        USER_ID  BARCODE FINAL_QUANTITY FINAL_SALE  \n",
       "1      62c08877baa38d1a1f6c211a      NaN           zero       1.49  \n",
       "9      66686fc2e04f743a096ea808      NaN           zero       2.29  \n",
       "17     63de64b1dcb50fbd3084f142      NaN           zero       2.49  \n",
       "18     6158642597d737581b5d30ee      NaN           1.00             \n",
       "60     5d4f08e962fb4a4a58574e7f      NaN           1.00             \n",
       "...                         ...      ...            ...        ...  \n",
       "49959  618c25125e388d4f513334b9      NaN           1.00       1.67  \n",
       "49960  665e2f887c0469953bfbdb5b      NaN           1.00       1.25  \n",
       "49962  61a8f120f6305b3dade12c15      NaN           1.00       1.29  \n",
       "49963  62f6799b30b23c82198fa01c      NaN           1.00       1.25  \n",
       "49994  5de7ec93ca63cc17893cdd14      NaN           1.00       3.00  \n",
       "\n",
       "[5762 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_df[transaction_df['BARCODE'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Taking a peek at the 5,762 records in the Transactions data that have a null Barcode to see if these seem like valid entries or any other explanation. From a quick look though it does appear that these items are for legit purchases there is just no item barcode attributed to them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Explore Summary\n",
    "  - With the abscence of a Barcode for some of the items in the PRODUCTS and TRANSACTION csv's there could be a chance that some of the purchased items in the reciepts will not be included in any analysis in a meaningful way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Clean up before SQLite DB load\n",
    "- Change all 'zero' entries in the FINAL_QUANTITY column of Transactions to 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df['FINAL_QUANTITY'] = transaction_df['FINAL_QUANTITY'].replace('zero', 0.00).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the CSV's into a SQLite database to write the SQL queries for Part II\n",
    "sql_connect = db.connect('takehome_db')\n",
    "\n",
    "#Loading each panda df into a table\n",
    "products_df.to_sql('products',sql_connect, if_exists= 'replace')\n",
    "user_df.to_sql('users',sql_connect, if_exists= 'replace')\n",
    "transaction_df.to_sql('transactions',sql_connect, if_exists= 'replace')\n",
    "\n",
    "#creating a cursor for running queries\n",
    "c = sql_connect.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed-Ended Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEQ #1 What are the top 5 brands by receipts scanned among users 21 and over?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             BRAND  receipts_scanned\n",
      "0      NERDS CANDY                 6\n",
      "1             DOVE                 6\n",
      "2          TRIDENT                 4\n",
      "3  SOUR PATCH KIDS                 4\n",
      "4           MEIJER                 4\n"
     ]
    }
   ],
   "source": [
    "#CE_Q_1\n",
    "query_1 = '''\n",
    "         with yr_old_user as (\n",
    "            select (JulianDay('now') - JulianDay(DATE(BIRTH_DATE)))/365.25 as user_age\n",
    "            , u.ID\n",
    "            from users u \n",
    "            where user_age >= 21\n",
    "        )\n",
    "\n",
    "        select p.BRAND\n",
    "            , count(t.RECEIPT_ID) as receipts_scanned\n",
    "        From transactions t\n",
    "            join yr_old_user yr\n",
    "               on t.USER_ID = yr.ID\n",
    "            join products p\n",
    "                on t.BARCODE = p.BARCODE\n",
    "                and p.brand is not null --< removing non-branded items so that we can target identifiable brands\n",
    "        group by p.brand\n",
    "        order by 2 desc\n",
    "        limit 5\n",
    "'''\n",
    "\n",
    "\n",
    "query_1_df = pd.read_sql_query(query_1, sql_connect)\n",
    "print(query_1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEQ #2 What are the top 5 brands by sales among users that have had their account for at least six months?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         BRAND  total_sales\n",
      "0          CVS        72.00\n",
      "1      TRIDENT        46.72\n",
      "2         DOVE        42.88\n",
      "3  COORS LIGHT        34.96\n",
      "4       QUAKER        16.60\n"
     ]
    }
   ],
   "source": [
    "#CE-Q-2\n",
    "query_2 = '''\n",
    "        with mt_old_user as (\n",
    "            select \n",
    "                (JulianDay('now') - JulianDay(DATE(CREATED_DATE)))  as account_age_days\n",
    "                , u.ID\n",
    "            from users u \n",
    "            where account_age_days >= 180 --limiting the user data set to accounts that have only been open for 6 months (180 days) or greater\n",
    "            )\n",
    "\n",
    "        select p.BRAND\n",
    "            , sum(FINAL_SALE) as total_sales\n",
    "        From transactions t\n",
    "            join mt_old_user mt\n",
    "               on t.USER_ID = mt.ID\n",
    "            join products p\n",
    "                on t.BARCODE = p.BARCODE\n",
    "                and p.brand is not null --< removing abscent brands so that we can get a clear understanding.\n",
    "        group by p.brand\n",
    "        order by 2 desc\n",
    "        limit 5 \n",
    "        \n",
    "'''\n",
    "\n",
    "\n",
    "query_2_df = pd.read_sql_query(query_2, sql_connect)\n",
    "print(query_2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEQ #3 What is the percentage of sales in the Health & Wellness category by generation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_generation  total_sales  percentage_of_total_sales\n",
      "0    Baby Boomers        89.03                      46.94\n",
      "1      Millenials        59.13                      31.18\n",
      "2    Generation X        41.50                      21.88\n"
     ]
    }
   ],
   "source": [
    "#CE-Q-3\n",
    "query_3 = '''\n",
    "        with user_gen as (\n",
    "            select \n",
    "                u.ID\n",
    "                , u.birth_date\n",
    "                , (strftime('%Y',BIRTH_DATE)*1) as birth_year\n",
    "                , case when (strftime('%Y',BIRTH_DATE)*1) <= 1927 then 'The Greatest Generation'\n",
    "                        when (strftime('%Y',BIRTH_DATE)*1) > 1927 and  (strftime('%Y',BIRTH_DATE)*1) <= 1945 then 'The Silent Generation'\n",
    "                        when (strftime('%Y',BIRTH_DATE)*1) > 1945 and  (strftime('%Y',BIRTH_DATE)*1) <= 1964 then 'Baby Boomers'\n",
    "                        when (strftime('%Y',BIRTH_DATE)*1) > 1964 and  (strftime('%Y',BIRTH_DATE)*1) <= 1980 then 'Generation X'\n",
    "                        when (strftime('%Y',BIRTH_DATE)*1) > 1980 and  (strftime('%Y',BIRTH_DATE)*1) <= 1996 then 'Millenials'\n",
    "                        when (strftime('%Y',BIRTH_DATE)*1) > 1996 and  (strftime('%Y',BIRTH_DATE)*1) <= 2009 then 'Generation Z'\n",
    "                        when (strftime('%Y',BIRTH_DATE)*1) > 2009 then 'Generation Alpha'\n",
    "                        end as user_generation\n",
    "            from users u \n",
    "            where true\n",
    "                and birth_date is not null\n",
    "            )\n",
    "\n",
    "        select ug.user_generation\n",
    "            , sum(t.FINAL_SALE) as total_sales\n",
    "            , ROUND(SUM(t.FINAL_SALE) * 100.0 / (SELECT SUM(FINAL_SALE) \n",
    "                                        FROM transactions t\n",
    "                                        JOIN user_gen ug \n",
    "                                          ON t.USER_ID = ug.ID\n",
    "                                        JOIN products p \n",
    "                                          ON t.BARCODE = p.BARCODE \n",
    "                                         AND p.CATEGORY_1 = 'Health & Wellness'), 2) AS percentage_of_total_sales\n",
    "        From transactions t\n",
    "            join user_gen ug\n",
    "               on t.USER_ID = ug.ID\n",
    "            join products p\n",
    "                on t.BARCODE = p.BARCODE\n",
    "                and p.CATEGORY_1 = 'Health & Wellness' \n",
    "        group by 1\n",
    "        order by 2 desc\n",
    "        \n",
    "       \n",
    "'''\n",
    "\n",
    "\n",
    "query_3_df = pd.read_sql_query(query_3, sql_connect)\n",
    "print(query_3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open-Ended Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OEQ #1 Who are Fetch’s power users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        USER_ID  distinct_receipts  total_dollars_spent  \\\n",
      "0      62925c1be942f00613f7365e                 10                49.87   \n",
      "1      64063c8880552327897186a5                  9                43.72   \n",
      "2      609af341659cf474018831fb                  7                25.55   \n",
      "3      6682cbf6465f309038ae1888                  6                37.47   \n",
      "4      653a0f40909604bae9071473                  4                84.78   \n",
      "...                         ...                ...                  ...   \n",
      "17689  599377a8e4b09f6f206e71d5                  1                 0.17   \n",
      "17690  598b822ae4b0465558c94765                  1                 7.48   \n",
      "17691  59725916e4b01bd2053089fe                  1                 5.98   \n",
      "17692  57af9582e4b06f40aeef6f63                  2                15.28   \n",
      "17693  56242219e4b07364e3e0bef4                  1                 3.18   \n",
      "\n",
      "       items_purchased  distinct_items_purchased  \n",
      "0                   20                        10  \n",
      "1                   18                         9  \n",
      "2                   14                         7  \n",
      "3                   12                         6  \n",
      "4                   12                         6  \n",
      "...                ...                       ...  \n",
      "17689                0                         0  \n",
      "17690                0                         0  \n",
      "17691                0                         0  \n",
      "17692                0                         0  \n",
      "17693                0                         0  \n",
      "\n",
      "[17694 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#OE-Q-1\n",
    "query_4 = '''\n",
    "        \n",
    "        select\n",
    "            USER_ID\n",
    "            , count(distinct RECEIPT_ID) as distinct_receipts\n",
    "            , sum(FINAL_SALE) as total_dollars_spent\n",
    "            , count(BARCODE) as items_purchased\n",
    "            , count(distinct BARCODE) as distinct_items_purchased\n",
    "        From transactions t\n",
    "        group by 1\n",
    "        order by 5 desc\n",
    "     \n",
    "       \n",
    "'''\n",
    "\n",
    "\n",
    "query_4_df = pd.read_sql_query(query_4, sql_connect)\n",
    "print(query_4_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining Fetch's power users could go in a few directions; the most amount of money spent, the most distinct checkouts registered (Distinct Receipts), the most amount of individual items purchased, the most distinct items purchased. So deciding what defines a power user to Fetch is important and I think it would depend on how Fetch monetizes its user purchase data. If fetch can create more value from using its user's information across many different brands than I think it would be better to focus on users who purchased more variety of items and we could market their information to more brands.\n",
    "\n",
    "- Which is where I left the last version of the query above to show the top user_ids for users who had made the most distinct list of items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OEQ #2 Which is the leading brand in the Dips & Salsa category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    BRAND  distinct_receipts  total_units_purchased  \\\n",
      "0                TOSTITOS                 36                   60.0   \n",
      "1                    None                 21                   35.0   \n",
      "2              GOOD FOODS                  9                   16.0   \n",
      "3                    PACE                 24                   38.0   \n",
      "4              MARKETSIDE                 16                   23.0   \n",
      "5                  FRITOS                 19                   33.0   \n",
      "6            HELUVA GOOD!                 15                   20.0   \n",
      "7    FRESHNESS GUARANTEED                 12                   17.0   \n",
      "8        DEAN'S DAIRY DIP                 17                   22.0   \n",
      "9                MARZETTI                 11                   19.0   \n",
      "10    HIDDEN VALLEY RANCH                  9                   13.0   \n",
      "11          HIDDEN VALLEY                 10                   22.0   \n",
      "12                 HERDEZ                  9                   12.0   \n",
      "13          PRIVATE LABEL                  9                   13.0   \n",
      "14     KIRKLAND SIGNATURE                  3                    5.0   \n",
      "15                  SABRA                  9                   16.0   \n",
      "16         FRESH CRAVINGS                  7                   10.0   \n",
      "17              LITEHOUSE                  4                    6.0   \n",
      "18          GOOD & GATHER                  5                    5.0   \n",
      "19                YUCATAN                  4                    4.0   \n",
      "20                  LAY'S                  6                   12.0   \n",
      "21           GORDO'S DIPS                  4                    6.0   \n",
      "22          MEMBER'S MARK                  4                    8.0   \n",
      "23                 WHOLLY                  3                    4.0   \n",
      "24                NUTELLA                  1                    1.0   \n",
      "25              MRS WAGES                  4                    6.0   \n",
      "26            BOAR'S HEAD                  2                    2.0   \n",
      "27            GREAT VALUE                  6                   14.0   \n",
      "28           NEWMAN’S OWN                  3                    6.0   \n",
      "29  MATEO'S GOURMET SALSA                  2                    3.0   \n",
      "30      PRIVATE SELECTION                  2                    2.0   \n",
      "31                 MEIJER                  2                    3.0   \n",
      "32               MURRAY'S                  2                    4.0   \n",
      "33      TACO BELL GROCERY                  2                    2.0   \n",
      "34                   FODY                  1                    1.0   \n",
      "35   ON THE BORDER SNACKS                  2                    3.0   \n",
      "36           DEAN'S DAIRY                  3                    5.0   \n",
      "37     TASTE OF THE SOUTH                  1                    1.0   \n",
      "38                 CLINTS                  1                    1.0   \n",
      "39              CHI-CHI'S                  2                    2.0   \n",
      "40                  BISON                  1                    1.0   \n",
      "41                MISSION                  1                    1.0   \n",
      "42                 JULIOS                  1                    2.0   \n",
      "43                 HILAND                  2                    3.0   \n",
      "44        CREAMLAND DAIRY                  1                    1.0   \n",
      "45                  DAISY                  1                    4.0   \n",
      "46         WELLSLEY FARMS                  1                    2.0   \n",
      "47       SIGNATURE SELECT                  1                    2.0   \n",
      "48          LA TERRA FINA                  1                    2.0   \n",
      "49          PRAIRIE FARMS                  3                    6.0   \n",
      "50                 MATEOS                  1                    2.0   \n",
      "51                   ESTI                  1                    2.0   \n",
      "52            ALWAYS SAVE                  1                    1.0   \n",
      "53        FRESH CREATIONS                  1                    2.0   \n",
      "54             O ORGANICS                  1                    2.0   \n",
      "55              FRITO-LAY                  1                    2.0   \n",
      "56                ISADORA                  1                    1.0   \n",
      "57           LA PREFERIDA                  1                    2.0   \n",
      "58                    UTZ                  1                    2.0   \n",
      "59                  ZACCA                  1                    1.0   \n",
      "\n",
      "    total_dollars_spent  \n",
      "0                260.99  \n",
      "1                154.37  \n",
      "2                118.89  \n",
      "3                118.58  \n",
      "4                103.29  \n",
      "5                 91.73  \n",
      "6                 85.46  \n",
      "7                 73.37  \n",
      "8                 67.97  \n",
      "9                 64.60  \n",
      "10                59.42  \n",
      "11                51.24  \n",
      "12                48.32  \n",
      "13                48.15  \n",
      "14                46.96  \n",
      "15                39.48  \n",
      "16                38.97  \n",
      "17                37.92  \n",
      "18                33.50  \n",
      "19                31.36  \n",
      "20                29.90  \n",
      "21                29.88  \n",
      "22                28.92  \n",
      "23                28.07  \n",
      "24                25.96  \n",
      "25                19.32  \n",
      "26                18.96  \n",
      "27                18.88  \n",
      "28                17.87  \n",
      "29                14.01  \n",
      "30                13.56  \n",
      "31                13.37  \n",
      "32                13.04  \n",
      "33                12.90  \n",
      "34                10.96  \n",
      "35                10.49  \n",
      "36                10.46  \n",
      "37                 9.96  \n",
      "38                 7.94  \n",
      "39                 7.14  \n",
      "40                 6.58  \n",
      "41                 6.56  \n",
      "42                 5.98  \n",
      "43                 5.83  \n",
      "44                 5.76  \n",
      "45                 5.58  \n",
      "46                 5.49  \n",
      "47                 5.49  \n",
      "48                 5.49  \n",
      "49                 5.34  \n",
      "50                 4.67  \n",
      "51                 3.99  \n",
      "52                 3.98  \n",
      "53                 3.69  \n",
      "54                 3.59  \n",
      "55                 3.50  \n",
      "56                 3.48  \n",
      "57                 2.88  \n",
      "58                 1.25  \n",
      "59                 0.00  \n"
     ]
    }
   ],
   "source": [
    "#OE-Q-2\n",
    "query_5 = '''\n",
    "        \n",
    "        select\n",
    "            p.BRAND\n",
    "            , count(distinct RECEIPT_ID) as distinct_receipts\n",
    "            , sum(FINAL_QUANTITY) as total_units_purchased\n",
    "            , sum(FINAL_SALE) as total_dollars_spent\n",
    "        From transactions t\n",
    "            join products p\n",
    "                on t.BARCODE = p.BARCODE\n",
    "                and p.CATEGORY_2 = 'Dips & Salsa' \n",
    "        group by 1\n",
    "        order by 4 desc\n",
    "        \n",
    "     \n",
    "       \n",
    "'''\n",
    "\n",
    "\n",
    "query_5_df = pd.read_sql_query(query_5, sql_connect)\n",
    "print(query_5_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I think it is safe to say that Tostitos is the leading Brand in the Dips & Salsas category, with them leading in the total dollars spent, units purchased, and total amount of distinct purchases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OEQ #3 At what percent has Fetch grown year over year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   scan_year  total_dollars_scanned\n",
      "0       2024               171614.4\n"
     ]
    }
   ],
   "source": [
    "#OE-Q-3\n",
    "query_6 = '''\n",
    "        \n",
    "        select\n",
    "           (strftime('%Y',SCAN_DATE)*1) as scan_year\n",
    "           , sum(FINAL_SALE) as total_dollars_scanned\n",
    "        From transactions t\n",
    "        group by 1      \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "query_6_df = pd.read_sql_query(query_6, sql_connect)\n",
    "print(query_6_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Transaction data provided is only for the year 2024 and in the months of June through September, so a true Year over Year analysis of Fetch's growth isn't really possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.close()\n",
    "sql_connect.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasrt III - Stakeholder Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After taking a look at the data provided and doing some initial analysis, there is data enrichment that could help a lot with finding actionable insight:\n",
    "    1. Building a more robust USER data set that has is able to be matched more with our TRANSACTION data, because to currently only be able to match 262 out of 50,000 transactions (0.5%) with User information is creating a serious gap in analytical ability.\n",
    "\n",
    "- An interesting insight from analyzing this data though is the large percentage that Baby Boomers make up for the overall sales in the 'Health & Wellness' category. Beating out both younger generations of Gen X and Millenials. This trend is great to see with the older population having good adoption of the Fetch platform and in a category that could be very lucrative. I think further analysis and possible engagement with the Boomer poplutaion could be a great opportunity as they tend to have more disposable income and liesure to shop. \n",
    "\n",
    "- Going forward I would like to work with a marketing and/or product leader to get a better definition of what a Power user is for Fetch, as well as work with engineering and data engineering stakeholders to better enrich the USER data to be able to attribute much more to the TRANSACTION data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
